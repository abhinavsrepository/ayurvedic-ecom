name: ML Service CI/CD

on:
  pull_request:
    branches: [main, develop]
    paths:
      - 'ml-service/**'
      - '.github/workflows/ml-service-ci.yml'
  push:
    branches: [main, develop]
    paths:
      - 'ml-service/**'
      - '.github/workflows/ml-service-ci.yml'
  release:
    types: [published]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'
  WORKING_DIRECTORY: './ml-service'

jobs:
  # Job 1: Lint & Format Check
  lint:
    name: Lint & Format Check
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WORKING_DIRECTORY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort pylint mypy
          pip install -r requirements.txt

      - name: Run Black (format check)
        run: black --check --diff .

      - name: Run isort (import sort check)
        run: isort --check-only --diff .

      - name: Run Flake8 (linting)
        run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Run Pylint
        run: pylint **/*.py || true

      - name: Run mypy (type checking)
        run: mypy . --ignore-missing-imports || true

  # Job 2: Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WORKING_DIRECTORY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pytest-asyncio pytest-mock
          pip install -r requirements.txt

      - name: Run pytest with coverage
        run: |
          pytest --cov=. --cov-report=xml --cov-report=html --cov-report=term-missing || true

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ env.WORKING_DIRECTORY }}/coverage.xml
          flags: ml-service
          name: ml-service
          fail_ci_if_error: false

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: ml-coverage-report
          path: ${{ env.WORKING_DIRECTORY }}/htmlcov
          retention-days: 30

  # Job 3: Model Validation
  model-validation:
    name: Model Validation & Testing
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WORKING_DIRECTORY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download/Validate ML models
        run: |
          echo "Validating ML models..."
          python -c "
          import os
          import pickle
          model_path = 'models/'
          if os.path.exists(model_path):
              for file in os.listdir(model_path):
                  if file.endswith('.pkl'):
                      filepath = os.path.join(model_path, file)
                      try:
                          with open(filepath, 'rb') as f:
                              model = pickle.load(f)
                          print(f'✓ Model {file} loaded successfully')
                      except Exception as e:
                          print(f'✗ Model {file} failed to load: {e}')
                          exit(1)
          else:
              print('No models directory found')
          "

      - name: Test model inference
        run: |
          echo "Testing model inference..."
          python -c "
          import sys
          sys.path.append('.')
          # Add your model inference tests here
          print('Model inference test completed')
          "

  # Job 4: Security Scan
  security-scan:
    name: Security & Vulnerability Scan
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WORKING_DIRECTORY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install safety
        run: |
          python -m pip install --upgrade pip
          pip install safety bandit

      - name: Run Safety (dependency vulnerabilities)
        run: safety check --file requirements.txt --json || true

      - name: Run Bandit (security issues)
        run: bandit -r . -f json -o bandit-report.json || true

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            ${{ env.WORKING_DIRECTORY }}/bandit-report.json
          retention-days: 30

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: ${{ env.WORKING_DIRECTORY }}
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # Job 5: Docker Build
  docker-build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: [lint, unit-tests, model-validation]
    if: github.ref == 'refs/heads/main' || github.event_name == 'release'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ secrets.DOCKER_USERNAME }}/ayurveda-ml-service
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ${{ env.WORKING_DIRECTORY }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ secrets.DOCKER_USERNAME }}/ayurveda-ml-service:buildcache
          cache-to: type=registry,ref=${{ secrets.DOCKER_USERNAME }}/ayurveda-ml-service:buildcache,mode=max
          build-args: |
            PYTHON_VERSION=${{ env.PYTHON_VERSION }}

      - name: Test Docker image
        run: |
          docker run --rm ${{ secrets.DOCKER_USERNAME }}/ayurveda-ml-service:latest python --version

  # Job 6: Performance Testing
  performance-tests:
    name: Performance & Load Tests
    runs-on: ubuntu-latest
    needs: [docker-build]
    if: github.ref == 'refs/heads/main'
    defaults:
      run:
        working-directory: ${{ env.WORKING_DIRECTORY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install locust pytest-benchmark
          pip install -r requirements.txt

      - name: Run performance benchmarks
        run: |
          echo "Running performance benchmarks..."
          python -c "
          import time
          import statistics

          # Simulate model inference performance test
          inference_times = []
          for i in range(100):
              start = time.time()
              # Add your model inference here
              time.sleep(0.01)  # Simulate inference
              inference_times.append(time.time() - start)

          avg_time = statistics.mean(inference_times)
          p95_time = statistics.quantiles(inference_times, n=20)[18]

          print(f'Average inference time: {avg_time*1000:.2f}ms')
          print(f'P95 inference time: {p95_time*1000:.2f}ms')

          # Fail if performance is below threshold
          if avg_time > 0.1:
              print('Performance below threshold!')
              exit(1)
          "

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: ${{ env.WORKING_DIRECTORY }}/performance-results.json
          retention-days: 30
        if: always()

  # Job 7: Deploy Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [docker-build, performance-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: staging

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to staging
        run: |
          echo "Deploying ML service to staging environment..."
          # Add your deployment commands here
          # Example: kubectl apply, helm upgrade, etc.

      - name: Run health check
        run: |
          echo "Running health check..."
          # Add health check commands here
          # Example: curl http://staging-ml-api/health

      - name: Run smoke tests
        run: |
          echo "Running smoke tests..."
          # Add smoke tests here

      - name: Notify team on Slack
        if: success()
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              text: ':robot: ML Service deployed to staging',
              attachments: [{
                color: 'good',
                text: `Commit: ${process.env.AS_COMMIT}\nBranch: ${process.env.AS_REF}\nAuthor: ${process.env.AS_AUTHOR}`
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Job 8: Deploy Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [docker-build]
    if: github.event_name == 'release'
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to production
        run: |
          echo "Deploying ML service to production environment..."
          # Add your deployment commands here

      - name: Run health check
        run: |
          echo "Running production health check..."
          # Add health check commands here

      - name: Monitor deployment
        run: |
          echo "Monitoring deployment..."
          # Add monitoring commands here

      - name: Create deployment notification
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              text: ':tada: ML Service deployed to production!',
              attachments: [{
                color: 'good',
                text: `Version: ${{ github.event.release.tag_name }}\nAuthor: ${process.env.AS_AUTHOR}`
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

      - name: Tag Docker image as stable
        run: |
          docker pull ${{ secrets.DOCKER_USERNAME }}/ayurveda-ml-service:${{ github.event.release.tag_name }}
          docker tag ${{ secrets.DOCKER_USERNAME }}/ayurveda-ml-service:${{ github.event.release.tag_name }} \
                     ${{ secrets.DOCKER_USERNAME }}/ayurveda-ml-service:stable
          docker push ${{ secrets.DOCKER_USERNAME }}/ayurveda-ml-service:stable
